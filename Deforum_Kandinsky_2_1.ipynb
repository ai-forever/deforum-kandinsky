{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to initialize NVML: Unknown Error\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "from deforum_kandinsky import KandinskyImg2ImgPipeline, DeforumKandinsky\n",
    "from diffusers import KandinskyPriorPipeline\n",
    "from transformers import CLIPVisionModelWithProjection\n",
    "from diffusers.models import UNet2DConditionModel\n",
    "import imageio.v2 as iio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import CLIPVisionModelWithProjection\n",
    "import ipywidgets as widgets\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create video from generated frames\n",
    "def frames2video(frames, output_path=\"video.mp4\", display_output=False):\n",
    "    writer = iio.get_writer(output_path, fps=24)\n",
    "    for frame in frames:\n",
    "        writer.append_data(np.array(frame))\n",
    "    writer.close()\n",
    "    if display_output:\n",
    "        display.Video(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kandinsky 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m image_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mCLIPVisionModelWithProjection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkandinsky-community/kandinsky-2-1-prior\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_encoder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m unet \u001b[38;5;241m=\u001b[39m UNet2DConditionModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkandinsky-community/kandinsky-2-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      9\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m     11\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m prior \u001b[38;5;241m=\u001b[39m KandinskyPriorPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkandinsky-community/kandinsky-2-1-prior\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     14\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m     15\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:2053\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2051\u001b[0m     )\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.imgenv-kandinsky-deforum-azizov-0/lib/python3.9/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "image_encoder = CLIPVisionModelWithProjection.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-1-prior\", \n",
    "    subfolder='image_encoder',\n",
    "    torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-1\", \n",
    "    subfolder='unet',\n",
    "    torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "prior = KandinskyPriorPipeline.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-1-prior\", \n",
    "    torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "decoder = KandinskyImg2ImgPipeline.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-1', \n",
    "    unet=unet, \n",
    "    torch_dtype=torch.float16\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define instance of Deforum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define instance of Deforum\n",
    "deforum = DeforumKandinsky(\n",
    "    prior=prior,\n",
    "    decoder_img2img=decoder,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Default Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation_widgets():\n",
    "    prompt = widgets.Text(\n",
    "        description='Prompt:', \n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    negative_prompt = widgets.Text(\n",
    "        description='Neg Prompt:', \n",
    "        value=\"low quility, bad image, cropped, out of frame\",\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    duration = widgets.FloatSlider(\n",
    "        description='Duration:', \n",
    "        min=0.25, max=60, \n",
    "        value=5, step=0.25, \n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    animation = widgets.RadioButtons(\n",
    "        options=[\"right\", \"left\", \"up\", \"down\", \"spin_clockwise\", \"spin_counterclockwise\", \"zoomin\", \"zoomout\" , \"live\"], \n",
    "        description='Animation Mode:'\n",
    "        )\n",
    "\n",
    "    animation = widgets.Dropdown(\n",
    "        options=[\"right\", \"left\", \"up\", \"down\", \"spin_clockwise\", \"spin_counterclockwise\", \"zoomin\", \"zoomout\" , \"live\"],\n",
    "        value=\"right\",\n",
    "        description='Number:',\n",
    "    )\n",
    "    return widgets.VBox(children=(prompt,negative_prompt, duration, animation))\n",
    "\n",
    "def create_video_settings():\n",
    "    return widgets.VBox(children=[\n",
    "        widgets.HTML(\"<h2>Video Settings</h2>\"),\n",
    "        widgets.BoundedIntText(\n",
    "            min=64,\n",
    "            max=1e6,\n",
    "            step=64,\n",
    "            value=640,\n",
    "            description='Width:',\n",
    "            disabled=False\n",
    "        ),\n",
    "        widgets.BoundedIntText(\n",
    "            min=64,\n",
    "            max=1e6,\n",
    "            step=64,\n",
    "            value=640,\n",
    "            description='Height:',\n",
    "            disabled=False\n",
    "        ),\n",
    "        widgets.IntSlider(\n",
    "            description='FPS',\n",
    "            min=1, \n",
    "            max=48, \n",
    "            value=24, \n",
    "            step=1\n",
    "        ),\n",
    "        widgets.Text(\n",
    "            description='output path:', \n",
    "            value = \"video.mp4\",\n",
    "        )\n",
    "    ])\n",
    "\n",
    "def create_animation_tabs():\n",
    "    an_widgets = widgets.Tab(layout=widgets.Layout(width='90%', height='100%'))\n",
    "    an_widgets.children = [create_animation_widgets()]\n",
    "\n",
    "    def update(a, an_widgets=an_widgets):\n",
    "        if an_widgets.children[-1].children[0].value:\n",
    "            an_widgets.children += (create_animation_widgets(),)\n",
    "        for index, child in enumerate(an_widgets.children):\n",
    "            an_widgets.set_title(index, child.children[0].value)\n",
    "\n",
    "    def clear(a, an_widgets=an_widgets):\n",
    "        children = list(an_widgets.children)\n",
    "        children.pop(an_widgets.selected_index)\n",
    "        an_widgets.children = tuple(children)\n",
    "        an_widgets.set_title(0, \"\")\n",
    "\n",
    "    add_button = widgets.Button(\n",
    "        description='Add Animation',\n",
    "        layout=widgets.Layout(width='44.75%')\n",
    "    )\n",
    "    add_button.style.button_color = \"blue\"\n",
    "    add_button.on_click(update)\n",
    "\n",
    "    clear_button = widgets.Button(\n",
    "        description='Remove Animation',\n",
    "        layout=widgets.Layout(width='44.75%')\n",
    "    )\n",
    "    clear_button.style.button_color = \"red\"\n",
    "    clear_button.on_click(clear)\n",
    "\n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h2>Animations</h2>\"), \n",
    "        an_widgets,\n",
    "        widgets.HBox([add_button, clear_button])\n",
    "    ])\n",
    "\n",
    "\n",
    "def create_start_button(animation_tabs, video_widgets, deforum, animation_display):\n",
    "    def render_deforum(animation, animation_display, output_path):\n",
    "        frames = []\n",
    "        with animation_display:\n",
    "            for frame, current_params in animation:\n",
    "                frames.append(frame)\n",
    "                    display.clear_output(wait=True)\n",
    "                    display.display(frame)\n",
    "        \n",
    "        if output_path and output_path.endswith(\".mp4\"):\n",
    "            frames2video(frames, output_path)\n",
    "        else: \n",
    "            frames2video(frames)\n",
    "            \n",
    "    def parse_args(_):\n",
    "        children = animation_tabs.children[1].children\n",
    "        prompts = []\n",
    "        negative_prompts = [] \n",
    "        durations = []\n",
    "        animations = []\n",
    "        for child in children:\n",
    "            prompt, negative_prompt, duration, animation = [x.value for x in child.children]\n",
    "            if prompt: \n",
    "                prompts.append(prompt)\n",
    "                negative_prompts.append(negative_prompt)\n",
    "                durations.append(int(duration))\n",
    "                animations.append(animation)\n",
    "                \n",
    "        width, height, fps = [int(x.value) for x in video_widgets.children[1:-1]]\n",
    "        output_path = video_widgets.children[-1].value\n",
    "        animation = deforum(\n",
    "            prompts=prompts,\n",
    "            negative_prompts=negative_prompts, \n",
    "            animations=animations, \n",
    "            prompt_durations=durations,\n",
    "            H=height,\n",
    "            W=width,\n",
    "            fps=fps,\n",
    "        )\n",
    "        render_deforum(tqdm(animation, total=len(deforum), animation_display, output_path)\n",
    "\n",
    "    button = widgets.Button(\n",
    "        description='Start Rendering!', \n",
    "        layout=widgets.Layout(width='90%')\n",
    "    )\n",
    "    button.on_click(parse_args)\n",
    "    return button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_widgets = create_video_settings()\n",
    "animation_tabs = create_animation_tabs()\n",
    "animation_display = widgets.Output()\n",
    "start_button = create_start_button(animation_tabs, video_widgets, deforum, animation_display)\n",
    "display.display(animation_display, video_widgets, animation_tabs, start_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define instance of Deforum\n",
    "deforum = DeforumKandinsky(\n",
    "    prior=prior,\n",
    "    decoder_img2img=decoder,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "            \n",
    "animation = deforum(\n",
    "    prompts=[\n",
    "        \"winter forest, snowflakes, Van Gogh style\",\n",
    "        \"spring forest, flowers, sun rays, Van Gogh style\",\n",
    "        \"summer forest, lake, reflections on the water, summer sun, Van Gogh style\",\n",
    "        \"autumn forest, rain, Van Gogh style\",\n",
    "        \"winter forest, snowflakes, Van Gogh style\",\n",
    "    ], \n",
    "    animations=['live', 'right', 'right', 'right', 'live'], \n",
    "    prompt_durations=[1, 1, 1, 1, 1],\n",
    "    H=640,\n",
    "    W=640,\n",
    "    fps=24,\n",
    "    save_samples=False,\n",
    "    sampler = \"euler\",\n",
    "    linear_transition=True,\n",
    ")\n",
    "\n",
    "frames = []\n",
    "\n",
    "out = Output()\n",
    "pbar = tqdm(animation, total=len(deforum))\n",
    "display.display(out)\n",
    "for frame, current_params in pbar:\n",
    "    frames.append(frame)\n",
    "    with out:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(frame)\n",
    "        for key, value in current_params.items():\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames2video(frames, \"output_2_1.mp4\", fps=4)\n",
    "Video(\"output_2_1.mp4\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "25b221746895226ff7c6b9d8aea8c62a9e808c88b786315a5ba5e4e82d158d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
