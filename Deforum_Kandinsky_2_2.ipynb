{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct  9 06:37:16 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.172.01   Driver Version: 450.172.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100 80GB PCIe      On   | 00000000:B9:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    55W / 300W |      0MiB / 81252MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "from deforum_kandinsky import KandinskyV22Img2ImgPipeline, DeforumKandinsky\n",
    "from diffusers import KandinskyV22PriorPipeline\n",
    "from transformers import CLIPVisionModelWithProjection\n",
    "from diffusers.models import UNet2DConditionModel\n",
    "import imageio.v2 as iio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create video from generated frames\n",
    "def frames2video(frames, output_path=\"video.mp4\", fps=24, display=False):\n",
    "    writer = iio.get_writer(output_path, fps=fps)\n",
    "    for frame in tqdm(frames):\n",
    "        writer.append_data(np.array(frame))\n",
    "    writer.close()\n",
    "    if display:\n",
    "        Video(url=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kandinsky 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5addde15700140e9a381401a4a7bfb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2767a3dc424fad9f6dae70be6ddd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "image_encoder = CLIPVisionModelWithProjection.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-prior', \n",
    "    subfolder='image_encoder'\n",
    "    ).to(torch.float16).to(device)\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-decoder', \n",
    "    subfolder='unet'\n",
    "    ).to(torch.float16).to(device)\n",
    "prior = KandinskyV22PriorPipeline.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-prior', \n",
    "    image_encoder=image_encoder, \n",
    "    torch_dtype=torch.float16,\n",
    "    ).to(device)\n",
    "decoder = KandinskyV22Img2ImgPipeline.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-decoder', \n",
    "    unet=unet,\n",
    "    torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "\n",
    "prior.set_progress_bar_config(disable=True)\n",
    "decoder.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Animation Using GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation_widgets():\n",
    "    prompt = widgets.Text(\n",
    "        description='Prompt:', \n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    negative_prompt = widgets.Text(\n",
    "        description='Neg Prompt:', \n",
    "        value=\"low quility, bad image, cropped, out of frame\",\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    duration = widgets.FloatSlider(\n",
    "        description='Duration:', \n",
    "        min=0.25, max=60, \n",
    "        value=5, step=0.25, \n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    acceleration = widgets.FloatSlider(\n",
    "        description='Acceleration:', \n",
    "        min=0.1, max=5, \n",
    "        value=1, step=0.1, \n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "\n",
    "    animation = widgets.Dropdown(\n",
    "        options=[\n",
    "            \"right\", \"left\", \n",
    "            \"up\", \"down\", \n",
    "            \"spin_clockwise\", \"spin_counterclockwise\", \n",
    "            \"zoomin\", \"zoomout\", \n",
    "            \"rotate_up\", \"rotate_down\", \n",
    "            \"rotate_left\", \"rotate_right\",\n",
    "            \"around_left\", \"around_right\",\n",
    "            \"flipping_phi\",\n",
    "            \"live\",\n",
    "        ],\n",
    "        value=\"right\",\n",
    "        description='Number:',\n",
    "    )\n",
    "    return widgets.VBox(children=(prompt,negative_prompt, duration, acceleration, animation))\n",
    "\n",
    "def create_video_settings():\n",
    "    return widgets.VBox(children=[\n",
    "        widgets.HTML(\"<h2>Video Settings</h2>\"),\n",
    "        widgets.BoundedIntText(\n",
    "            min=64,\n",
    "            max=1e6,\n",
    "            step=64,\n",
    "            value=640,\n",
    "            description='Width:',\n",
    "            disabled=False\n",
    "        ),\n",
    "        widgets.BoundedIntText(\n",
    "            min=64,\n",
    "            max=1e6,\n",
    "            step=64,\n",
    "            value=640,\n",
    "            description='Height:',\n",
    "            disabled=False\n",
    "        ),\n",
    "        widgets.IntSlider(\n",
    "            description='FPS',\n",
    "            min=1, \n",
    "            max=48, \n",
    "            value=24, \n",
    "            step=1\n",
    "        ),\n",
    "        widgets.Text(\n",
    "            description='output path:', \n",
    "            value = \"video.mp4\",\n",
    "        )\n",
    "    ])\n",
    "\n",
    "def create_animation_tabs():\n",
    "    an_widgets = widgets.Tab(layout=widgets.Layout(width='90%', height='100%'))\n",
    "    an_widgets.children = [create_animation_widgets()]\n",
    "\n",
    "    def update(a, an_widgets=an_widgets):\n",
    "        if an_widgets.children[-1].children[0].value:\n",
    "            an_widgets.children += (create_animation_widgets(),)\n",
    "        for index, child in enumerate(an_widgets.children):\n",
    "            an_widgets.set_title(index, child.children[0].value)\n",
    "\n",
    "    def clear(a, an_widgets=an_widgets):\n",
    "        children = list(an_widgets.children)\n",
    "        children.pop(an_widgets.selected_index)\n",
    "        an_widgets.children = tuple(children)\n",
    "        an_widgets.set_title(0, \"\")\n",
    "\n",
    "    add_button = widgets.Button(\n",
    "        description='Add Animation',\n",
    "        layout=widgets.Layout(width='44.75%')\n",
    "    )\n",
    "    add_button.style.button_color = \"blue\"\n",
    "    add_button.on_click(update)\n",
    "\n",
    "    clear_button = widgets.Button(\n",
    "        description='Remove Animation',\n",
    "        layout=widgets.Layout(width='44.75%')\n",
    "    )\n",
    "    clear_button.style.button_color = \"red\"\n",
    "    clear_button.on_click(clear)\n",
    "\n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h2>Animations</h2>\"), \n",
    "        an_widgets,\n",
    "        widgets.HBox([add_button, clear_button])\n",
    "    ])\n",
    "\n",
    "\n",
    "def create_start_button(animation_tabs, video_widgets, deforum, animation_display):\n",
    "    def render_deforum(animation, animation_display, output_path):\n",
    "        frames = []\n",
    "        with animation_display:\n",
    "            start_time = datetime.datetime.now() \n",
    "            progress = widgets.IntProgress(value=0, min=0, max=len(deforum))\n",
    "            for index, item in enumerate(animation):\n",
    "                image = item.pop(\"image\", None)\n",
    "                frames.append(image)\n",
    "                progress.value = index+1\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(image, progress)\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                elapsed_time -= datetime.timedelta(microseconds=elapsed_time.microseconds)\n",
    "                estimated_time = (elapsed_time/(index+1)*len(deforum))\n",
    "                estimated_time -= datetime.timedelta(microseconds=estimated_time.microseconds)\n",
    "                \n",
    "                print(f\"estimated_time: {elapsed_time}/{estimated_time}\")\n",
    "                for key, value in item.items(): \n",
    "                    print(f\"{key}: {value}\")\n",
    "                \n",
    "            progress.style.bar_color = 'green'\n",
    "        if output_path and output_path.endswith(\".mp4\"):\n",
    "            frames2video(frames, output_path)\n",
    "        else: \n",
    "            frames2video(frames)\n",
    "        \n",
    "            \n",
    "    def parse_args(_):\n",
    "        children = animation_tabs.children[1].children\n",
    "        prompts = []\n",
    "        negative_prompts = [] \n",
    "        durations = []\n",
    "        animations = []\n",
    "        accelerations = []\n",
    "        \n",
    "        for child in children:\n",
    "            prompt, negative_prompt, duration, acceleration, animation = [x.value for x in child.children]\n",
    "            if prompt: \n",
    "                prompts.append(prompt)\n",
    "                negative_prompts.append(negative_prompt)\n",
    "                durations.append(duration)\n",
    "                accelerations.append(acceleration)\n",
    "                animations.append(animation)\n",
    "                \n",
    "        width, height, fps = [int(x.value) for x in video_widgets.children[1:-1]]\n",
    "        output_path = video_widgets.children[-1].value\n",
    "        animation = deforum(\n",
    "            prompts=prompts,\n",
    "            negative_prompts=negative_prompts, \n",
    "            animations=animations, \n",
    "            prompt_durations=durations,\n",
    "            accelerations=accelerations,\n",
    "            H=height,\n",
    "            W=width,\n",
    "            fps=fps,\n",
    "            sampler=\"euler\"\n",
    "        )\n",
    "        animation = tqdm(animation, total=len(deforum))\n",
    "        render_deforum(animation, animation_display, output_path)\n",
    "\n",
    "    button = widgets.Button(\n",
    "        description='Start Rendering!', \n",
    "        layout=widgets.Layout(width='90%')\n",
    "    )\n",
    "    button.on_click(parse_args)\n",
    "    return button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57134cae0924f3f9b50ac533ebf98be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e93a2ba27d449bbc3e6cfb4aac3cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Video Settings</h2>'), BoundedIntText(value=640, description='Width:', max=1000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711a813666554f8f94c6e014ef33298d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Animations</h2>'), Tab(children=(VBox(children=(Text(value='', description='Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03c7d53654c4e42a81dfbef36155ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Start Rendering!', layout=Layout(width='90%'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define instance of Deforum\n",
    "deforum = DeforumKandinsky(\n",
    "    prior=prior,\n",
    "    decoder_img2img=decoder,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "video_widgets = create_video_settings()\n",
    "animation_tabs = create_animation_tabs()\n",
    "animation_display = widgets.Output()\n",
    "start_button = create_start_button(animation_tabs, video_widgets, deforum, animation_display)\n",
    "display.display(animation_display, video_widgets, animation_tabs, start_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.Video(url=\"video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Animation Using Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0670cb1e124062970faf02c73b1473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"output_2_2.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# define instance of Deforum\n",
    "deforum = DeforumKandinsky(\n",
    "    prior=prior,\n",
    "    decoder_img2img=decoder,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "prompts=[\n",
    "    # \"Futuristic multi-level smart city, matrix, night city, neon, a lot of greenery, maximum detail, HD, 8k\",\n",
    "    # \"Futuristic multi-level smart city, matrix, yearly morning city, neon, yellow sky, sunrise, a lot of greenery, maximum detail, HD, 8k\",\n",
    "    # \"Futuristic multi-level smart city, matrix, a lot of light, afternoon, a lot of greenery, maximum detail, HD, 8k\",\n",
    "    # \"Futuristic multi-level smart city, matrix, a lot of light, the sun is at its zenith, noon, a lot of greenery, maximum detail, HD, 8k\",\n",
    "    # \"Futuristic multi-level smart city, matrix, sunset, the sky is pink, a lot of greenery, maximum detail, HD, 8k\",\n",
    "    # \"Futuristic multi-level smart city, matrix, night city, neon, a lot of greenery, maximum detail, HD, 8k\",\n",
    "    # \"a boat with sails floats on the waves, sea waves, sunny day, style of the artist Katsushika Hokusai\",\n",
    "    \"watership, artstation, 16k\"\n",
    "]\n",
    "\n",
    "animation = deforum(\n",
    "    prompts=prompts,\n",
    "    animations = [\"right\"]*len(prompts),\n",
    "    prompt_durations=[3]*len(prompts),\n",
    "    accelerations = [15]*len(prompts),\n",
    "    H=640,\n",
    "    W=640,\n",
    "    fps=24,\n",
    "    save_samples=False,\n",
    "    linear_transition=False,\n",
    "    diffusion_cadence=\"2\",\n",
    "    # translation_y = \"0:(sin(3.14*t/48))\"\n",
    ")\n",
    "\n",
    "frames = []\n",
    "\n",
    "out = widgets.Output()\n",
    "pbar = tqdm(animation, total=len(deforum))\n",
    "display.display(out)\n",
    "\n",
    "os.makedirs(\"output/1/images\", exist_ok=True)\n",
    "os.makedirs(\"output/1/prev_images\", exist_ok=True)\n",
    "os.makedirs(\"output/1/depth_images\", exist_ok=True)\n",
    "with out:\n",
    "    for index, item in enumerate(pbar):\n",
    "        image = item.pop('image', None)\n",
    "        frames.append(image)\n",
    "        display.clear_output(wait=True) \n",
    "        \n",
    "        image.save(f\"output/1/images/{index}.jpg\")\n",
    "        if item[\"prev_image\"]:\n",
    "            item[\"prev_image\"].save(f\"output/1/prev_images/{index}.jpg\")\n",
    "        if item['depth'] is not None:\n",
    "            if isinstance(item[\"depth\"], torch.Tensor):\n",
    "                item[\"depth\"] = Image.fromarray((item[\"depth\"].detach().cpu().clamp(0, 1).numpy()).astype(np.uint8))\n",
    "            item[\"depth\"].save(f\"output/1/depth_images/{index}.jpg\")\n",
    "        image.save(f\"output/1/images/{index}.jpg\")\n",
    "        if item[\"prev_image\"]:\n",
    "            display.display(image, item[\"prev_image\"], item[\"depth\"])\n",
    "        # for key, value in item.items():\n",
    "            # if key == \"prev_image\": continue\n",
    "            # print(f\"{key}: {value}\")\n",
    "\n",
    "display.clear_output(wait=True) \n",
    "frames2video(frames, \"output_2_2.mp4\", fps=24)\n",
    "display.Video(url=\"output_2_2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames2video(frames, \"output_2_2.mp4\", fps=24)\n",
    "display.Video(url=\"output_2_2.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create per-frame Animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeforumAnimArgs():\n",
    "\n",
    "    #@markdown ####**Animation:**\n",
    "    animation_mode = \"3D\" #@param ['None', '2D', '3D', 'Video Input', 'Interpolation'] {type:'string'}\n",
    "    max_frames = 1 #@param {type:\"number\"}\n",
    "    border = 'replicate' #@param ['wrap', 'replicate'] {type:'string'}\n",
    "\n",
    "    #@markdown ####**Motion Parameters:**\n",
    "    angle = \"0:(0)\"#@param {type:\"string\"}\n",
    "    zoom = \"0:(1.00)\"#@param {type:\"string\"}\n",
    "    translation_x = \"0:(0)\"#@param {type:\"string\"}\n",
    "    translation_y = \"0:(0)\"#@param {type:\"string\"}\n",
    "    translation_z = \"0:(0)\"#@param {type:\"string\"}\n",
    "    rotation_3d_x = \"0:(0)\"#@param {type:\"string\"}\n",
    "    rotation_3d_y = \"0:(0)\"#@param {type:\"string\"}\n",
    "    rotation_3d_z = \"0:(0)\"#@param {type:\"string\"}\n",
    "    flip_2d_perspective = True #@param {type:\"boolean\"}\n",
    "    perspective_flip_theta = \"0:(0)\"#@param {type:\"string\"}\n",
    "    perspective_flip_phi = \"0:(0)\"#@param {type:\"string\"}\n",
    "    perspective_flip_gamma = \"0:(0)\"#@param {type:\"string\"}\n",
    "    perspective_flip_fv = \"0:(56)\"#@param {type:\"string\"}\n",
    "    noise_schedule = \"0: (0.02)\"#@param {type:\"string\"}\n",
    "    strength_schedule = \"0: (0.2)\"#@param {type:\"string\"}\n",
    "    contrast_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
    "    hybrid_comp_alpha_schedule = \"0:(1)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_blend_alpha_schedule = \"0:(0.5)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_contrast_schedule = \"0:(1)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_auto_contrast_cutoff_high_schedule =  \"0:(100)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_auto_contrast_cutoff_low_schedule =  \"0:(0)\" #@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Sampler Scheduling:**\n",
    "    enable_schedule_samplers = False #@param {type:\"boolean\"}\n",
    "    sampler_schedule = \"0:('euler'),10:('dpm2'),20:('dpm2_ancestral'),30:('heun'),40:('euler'),50:('euler_ancestral'),60:('dpm_fast'),70:('dpm_adaptive'),80:('dpmpp_2s_a'),90:('dpmpp_2m')\" #@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Unsharp mask (anti-blur) Parameters:**\n",
    "    kernel_schedule = \"0: (5)\"#@param {type:\"string\"}\n",
    "    sigma_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
    "    amount_schedule = \"0: (0.2)\"#@param {type:\"string\"}\n",
    "    threshold_schedule = \"0: (0.0)\"#@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Coherence:**\n",
    "    color_coherence = 'None' #@param ['None', 'Match Frame 0 HSV', 'Match Frame 0 LAB', 'Match Frame 0 RGB', 'Video Input'] {type:'string'}\n",
    "    color_coherence_video_every_N_frames = 1 #@param {type:\"integer\"}\n",
    "    color_force_grayscale = False #@param {type:\"boolean\"}\n",
    "    diffusion_cadence = '2' #@param ['1','2','3','4','5','6','7','8'] {type:'string'}\n",
    "\n",
    "    #@markdown ####**3D Depth Warping:**\n",
    "    use_depth_warping = True #@param {type:\"boolean\"}\n",
    "    midas_weight = 0.3#@param {type:\"number\"}\n",
    "    near_plane = 200\n",
    "    far_plane = 10000\n",
    "    fov = 40#@param {type:\"number\"}\n",
    "    padding_mode = 'border'#@param ['border', 'reflection', 'zeros'] {type:'string'}\n",
    "    sampling_mode = 'bicubic'#@param ['bicubic', 'bilinear', 'nearest'] {type:'string'}\n",
    "    save_depth_maps = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown ####**Video Input:**\n",
    "    video_init_path =None#@param {type:\"string\"}\n",
    "    extract_nth_frame = 1#@param {type:\"number\"}\n",
    "    overwrite_extracted_frames = True #@param {type:\"boolean\"}\n",
    "    use_mask_video = False #@param {type:\"boolean\"}\n",
    "    video_mask_path ='/content/video_in.mp4'#@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Hybrid Video for 2D/3D Animation Mode:**\n",
    "    hybrid_generate_inputframes = False #@param {type:\"boolean\"}\n",
    "    hybrid_use_first_frame_as_init_image = True #@param {type:\"boolean\"}\n",
    "    hybrid_motion = \"None\" #@param ['None','Optical Flow','Perspective','Affine']\n",
    "    hybrid_motion_use_prev_img = False #@param {type:\"boolean\"}\n",
    "    hybrid_flow_method = \"DIS Medium\" #@param ['DenseRLOF','DIS Medium','Farneback','SF']\n",
    "    hybrid_composite = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_mask_type = \"None\" #@param ['None', 'Depth', 'Video Depth', 'Blend', 'Difference']\n",
    "    hybrid_comp_mask_inverse = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_mask_equalize = \"None\" #@param  ['None','Before','After','Both']\n",
    "    hybrid_comp_mask_auto_contrast = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_save_extra_frames = False #@param {type:\"boolean\"}\n",
    "    hybrid_use_video_as_mse_image = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown ####**Interpolation:**\n",
    "    interpolate_key_frames = False #@param {type:\"boolean\"}\n",
    "    interpolate_x_frames = 20 #@param {type:\"number\"}\n",
    "    \n",
    "    #@markdown ####**Resume Animation:**\n",
    "    resume_from_timestring = False #@param {type:\"boolean\"}\n",
    "    resume_timestring = \"20220829210106\" #@param {type:\"string\"}\n",
    "\n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def DeforumArgs():\n",
    "    #@markdown **Image Settings**\n",
    "    W = 128 * 5#@param\n",
    "    H = 128 * 5 #@param\n",
    "    W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
    "    bit_depth_output = 8 #@param [8, 16, 32] {type:\"raw\"}\n",
    "\n",
    "    #@markdown **Sampling Settings**\n",
    "    seed = -1 #@param\n",
    "    prior_seed = 0\n",
    "    \n",
    "    sampler = 'euler_ancestral' #@param [\"klms\",\"dpm2\",\"dpm2_ancestral\",\"heun\",\"euler\",\"euler_ancestral\",\"plms\", \"ddim\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_a\", \"dpmpp_2m\"]\n",
    "    steps = 100 #@param\n",
    "    scale = 7 #@param\n",
    "    ddim_eta = 0.0 #@param\n",
    "    dynamic_threshold = None\n",
    "    static_threshold = None   \n",
    "\n",
    "    #@markdown **Save & Display Settings**\n",
    "    save_samples = False #@param {type:\"boolean\"}\n",
    "    save_settings = False #@param {type:\"boolean\"}\n",
    "    save_sample_per_step = False #@param {type:\"boolean\"}\n",
    "    \n",
    "    verbose = True\n",
    "    display_samples = True #@param {type:\"boolean\"}\n",
    "    show_sample_per_step = True #@param {type:\"boolean\"}\n",
    "    \n",
    "    #@markdown **Batch Settings**\n",
    "    n_batch = 1 #@param\n",
    "    n_samples = 1 #@param\n",
    "    filename_format = \"{timestring}_{index}_{prompt}.png\" #@param [\"{timestring}_{index}_{seed}.png\",\"{timestring}_{index}_{prompt}.png\"]\n",
    "    seed_behavior = \"iter\" #@param [\"iter\",\"fixed\",\"random\",\"ladder\",\"alternate\"]\n",
    "    seed_iter_N = 1 #@param {type:'integer'}\n",
    "    make_grid = False #@param {type:\"boolean\"}\n",
    "    grid_rows = 2 #@param \n",
    "    outdir = \"output\"\n",
    "\n",
    "    #@markdown **True Settings**\n",
    "    use_init = False #@param {type:\"boolean\"}\n",
    "    strength = 0.2 #@param {type:\"number\"}\n",
    "    strength_0_no_init = True # Set the strength to 0 automatically when no init image is used\n",
    "    init_image = None\n",
    "    # init_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
    "    add_init_noise = False #@param {type:\"boolean\"}\n",
    "    init_noise = 0.01 #@param\n",
    "    # Whiter areas of the mask are areas that change more\n",
    "    use_mask = False #@param {type:\"boolean\"}\n",
    "    use_alpha_as_mask = False # use the alpha channel of the init image as the mask\n",
    "    mask_file = \"https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg\" #@param {type:\"string\"}\n",
    "    invert_mask = False #@param {type:\"boolean\"}\n",
    "    # Adjust mask image, 1.0 is no adjustment. Should be positive numbers.\n",
    "    mask_brightness_adjust = 1.0  #@param {type:\"number\"}\n",
    "    mask_contrast_adjust = 1.0  #@param {type:\"number\"}\n",
    "    # Overlay the masked image at the end of the generation so it does not get degraded by encoding and decoding\n",
    "    overlay_mask = True  # {type:\"boolean\"}\n",
    "    # Blur edges of final overlay mask, if used. Minimum = 0 (no blur)\n",
    "    mask_overlay_blur = 5 # {type:\"number\"}\n",
    "\n",
    "    #@markdown **Exposure/Contrast Conditional Settings**\n",
    "    mean_scale = 0 #@param {type:\"number\"}\n",
    "    var_scale = 0 #@param {type:\"number\"}\n",
    "    exposure_scale = 0 #@param {type:\"number\"}\n",
    "    exposure_target = 0.7 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **Color Match Conditional Settings**\n",
    "    colormatch_scale = 0 #@param {type:\"number\"}\n",
    "    colormatch_image = \"https://www.saasdesign.io/wp-content/uploads/2021/02/palette-3-min-980x588.png\" #@param {type:\"string\"}\n",
    "    colormatch_n_colors = 4 #@param {type:\"number\"}\n",
    "    ignore_sat_weight = 0 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **CLIP\\Aesthetics Conditional Settings**\n",
    "    clip_name = 'ViT-L/14' #@param ['ViT-L/14', 'ViT-L/14@336px', 'ViT-B/16', 'ViT-B/32']\n",
    "    clip_scale = 0 #@param {type:\"number\"}\n",
    "    aesthetics_scale = 0 #@param {type:\"number\"}\n",
    "    cutn = 1 #@param {type:\"number\"}\n",
    "    cut_pow = 0.0001 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **Other Conditional Settings**\n",
    "    init_mse_scale = 0 #@param {type:\"number\"}\n",
    "    init_mse_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
    "    blue_scale = 0 #@param {type:\"number\"}\n",
    "    \n",
    "    #@markdown **Conditional Gradient Settings**\n",
    "    gradient_wrt = 'x0_pred' #@param [\"x\", \"x0_pred\"]\n",
    "    gradient_add_to = 'both' #@param [\"cond\", \"uncond\", \"both\"]\n",
    "    decode_method = 'linear' #@param [\"autoencoder\",\"linear\"]\n",
    "    grad_threshold_type = 'dynamic' #@param [\"dynamic\", \"static\", \"mean\", \"schedule\"]\n",
    "    clamp_grad_threshold = 0.2 #@param {type:\"number\"}\n",
    "    clamp_start = 0.2 #@param\n",
    "    clamp_stop = 0.01 #@param\n",
    "    grad_inject_timing = list(range(1,10)) #@param\n",
    "\n",
    "    #@markdown **Speed vs VRAM Settings**\n",
    "    cond_uncond_sync = True #@param {type:\"boolean\"}\n",
    "    precision = 'autocast' \n",
    "    C = 4\n",
    "    f = 8\n",
    "\n",
    "    cond_prompt = \"\"\n",
    "    cond_prompts = \"\"\n",
    "    uncond_prompt = \"\"\n",
    "    uncond_prompts = \"\"\n",
    "    timestring = \"\"\n",
    "    init_latent = None\n",
    "    init_sample = None\n",
    "    init_sample_raw = None\n",
    "    mask_sample = None\n",
    "    init_c = None\n",
    "    seed_internal = 0\n",
    "\n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "image_encoder = CLIPVisionModelWithProjection.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-prior', \n",
    "    subfolder='image_encoder'\n",
    "    ).to(torch.float16).to(device)\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-decoder', \n",
    "    subfolder='unet'\n",
    "    ).to(torch.float16).to(device)\n",
    "\n",
    "prior = KandinskyV22PriorPipeline.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-prior', \n",
    "    image_encoder=image_encoder, \n",
    "    torch_dtype=torch.float16,\n",
    "    ).to(device)\n",
    "decoder = KandinskyV22Img2ImgPipeline.from_pretrained(\n",
    "    'kandinsky-community/kandinsky-2-2-decoder', \n",
    "    unet=unet,\n",
    "    torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "\n",
    "prior.set_progress_bar_config(disable=True)\n",
    "decoder.set_progress_bar_config(disable=True)\n",
    "\n",
    "# define instance of Deforum\n",
    "deforum = DeforumKandinsky(\n",
    "    prior=prior,\n",
    "    decoder_img2img=decoder,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from deforum_kandinsky import render_animation, render_image_batch, render_interpolation, render_input_video\n",
    "from deforum_kandinsky.helpers.prompts import Prompts\n",
    "\n",
    "animation_prompts = {\n",
    "    0: \"a beautiful apple, trending on Artstation\",\n",
    "    24: \"a beautiful banana, trending on Artstation\",\n",
    "    48: \"a beautiful coconut, trending on Artstation\",\n",
    "    72: \"a beautiful durian, trending on Artstation\",\n",
    "}\n",
    "negative_prompts = {\n",
    "    0: \"bad image, cropped image\"\n",
    "}\n",
    "cond, uncond = Prompts(prompt=animation_prompts, neg_prompt=negative_prompts).as_dict()\n",
    "args = SimpleNamespace(**DeforumArgs())\n",
    "anim_args = SimpleNamespace(**DeforumAnimArgs())\n",
    "anim_args.max_frames = 96+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deforum_kandinsky import render_animation\n",
    "\n",
    "pbar = tqdm(render_animation(deforum.root, anim_args, args, cond, uncond), total=anim_args.max_frames-1)\n",
    "frames = []\n",
    "out =  widgets.Output()\n",
    "display.display(out)\n",
    "with out:\n",
    "    for item in pbar:\n",
    "        image = item.pop('image', None)\n",
    "        frames.append(image)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(image)\n",
    "        for key, value in item.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "display.clear_output(wait=False)\n",
    "frames2video(frames, \"output_2_2.mp4\", fps=24)\n",
    "display.Video(url=\"output_2_2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deforum_kandinsky import render_image_batch\n",
    "image_batch = [item[\"image\"] for item in tqdm(render_image_batch(deforum.root, args, cond, uncond), total=args.n_batch*len(cond))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display(*image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, math, os, pathlib, subprocess, sys, time, random\n",
    "\n",
    "animation_prompts = {\n",
    "    0: \"a beautiful neon car, trending on Artstation\",\n",
    "}\n",
    "negative_prompts = {\n",
    "    0: \"bad image, cropped image\"\n",
    "}\n",
    "cond, uncond = Prompts(prompt=animation_prompts, neg_prompt=negative_prompts).as_dict()\n",
    "\n",
    "args = SimpleNamespace(**DeforumArgs())\n",
    "anim_args = SimpleNamespace(**DeforumAnimArgs())\n",
    "\n",
    "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
    "args.strength = max(0.0, min(1.0, args.strength))\n",
    "\n",
    "if args.seed == -1:\n",
    "    args.seed = random.randint(0, 2**32 - 1)\n",
    "if not args.use_init:\n",
    "    args.init_image = None\n",
    "if args.sampler == 'plms' and (args.use_init or anim_args.animation_mode != 'None'):\n",
    "    print(f\"Init images aren't supported with PLMS yet, switching to KLMS\")\n",
    "    args.sampler = 'klms'\n",
    "if args.sampler != 'ddim':\n",
    "    args.ddim_eta = 0\n",
    "\n",
    "if anim_args.animation_mode == 'None':\n",
    "    anim_args.max_frames = 1\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    args.use_init = True\n",
    "\n",
    "# clean up unused memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "anim_args.video_init_path = \"video.mp4\"\n",
    "anim_args.animation_mode = 'Video Input'\n",
    "\n",
    "\n",
    "# dispatch to appropriate renderer\n",
    "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
    "    animation = render_animation(deforum.root, anim_args, args, cond, uncond)\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    animation = render_input_video(deforum.root, anim_args, args, cond, uncond)\n",
    "elif anim_args.animation_mode == 'Interpolation':\n",
    "    animation = render_interpolation(deforum.root, anim_args, args, cond, uncond)\n",
    "else:\n",
    "    animation = render_image_batch(deforum.root, args, cond, uncond)  \n",
    "\n",
    "pbar = tqdm(animation, total=anim_args.max_frames-1)\n",
    "frames = []\n",
    "out =  widgets.Output()\n",
    "display.display(out)\n",
    "with out:\n",
    "    for item in pbar:\n",
    "        image = item.pop('image', None)\n",
    "        frames.append(image)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(image)\n",
    "        for key, value in item.items():\n",
    "            print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "25b221746895226ff7c6b9d8aea8c62a9e808c88b786315a5ba5e4e82d158d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
